<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>RBERT: Cutting Edge NLP in R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jon Harmon" />
    <meta name="date" content="2019-11-09" />
    <link href="rbert_files/remark-css/default.css" rel="stylesheet" />
    <link href="rbert_files/remark-css/hygge.css" rel="stylesheet" />
    <link href="rbert_files/remark-css/robot-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">


name: title
class: inverse, center, middle



&lt;img src="img/rbert_hex.png" width = "300px"/&gt;

## Cutting-Edge NLP in R

.Large[Jon Harmon | DCR | 9 November 2019]

---

name: acknowledgement

# RBERT Lead Author

.pull-left[
![Jonathan Bratt](img/bratt-headshot.png)
]

.pull-right[
## Jonathan Bratt
###Macmillan Learning
###github.com/jonathanbratt
]

---

name: outline

# Outline

.Large[
* Transfer Learning
* BERT
* RBERT &amp; RBERTviz
* Attention
* Layer Outputs
]

---

# Transfer Learning

.pull-left[
.Large[
* Task: Classify images (ImageNet)
]
]

---

count: false

# Transfer Learning

.pull-left[
.Large[
* Task: Classify images (ImageNet)
* Early layers: simple features.
]]

&lt;div width="50%"&gt;
&lt;p  style="padding-left:10"&gt;Credit: &lt;a href="http://yosinski.com/deepvis"&gt;deepvis&lt;/a&gt; by Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson&lt;/p&gt;
&lt;div width="50%" style="float:left"&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-dark_to_light.png" width="130px"\&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-light_to_dark.png" width="130px"\&gt;
&lt;/div&gt;
&lt;div width="50%" style="float:right"&gt;
&lt;/div&gt;
&lt;/div&gt;

---

count: false

# Transfer Learning

.pull-left[
.Large[
* Task: Classify images (ImageNet)
* Early layers: simple features.
* Later layers: complex features.
]]

&lt;div width="50%"&gt;
&lt;p  style="padding-left:10"&gt;Credit: &lt;a href="http://yosinski.com/deepvis"&gt;deepvis&lt;/a&gt; by Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson&lt;/p&gt;
&lt;div width="50%" style="float:left"&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-dark_to_light.png" width="130px"\&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-light_to_dark.png" width="130px"\&gt;
&lt;/div&gt;
&lt;div width="50%" style="float:right"&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-faces.png" width="130px"\&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-text.png" width="130px"\&gt;
&lt;/div&gt;
&lt;/div&gt;

---

count: false

# Transfer Learning

.pull-left[
.Large[
* Task: Classify images (ImageNet)
* Early layers: simple features.
* Later layers: complex features.
* Features can transfer to many tasks.
]
]

&lt;div width="50%"&gt;
&lt;p  style="padding-left:10"&gt;Credit: &lt;a href="http://yosinski.com/deepvis"&gt;deepvis&lt;/a&gt; by Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson&lt;/p&gt;
&lt;div width="50%" style="float:left"&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-dark_to_light.png" width="130px"\&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-light_to_dark.png" width="130px"\&gt;
&lt;/div&gt;
&lt;div width="50%" style="float:right"&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-faces.png" width="130px"\&gt;
&lt;img src="img/deep_viz/deep_viz_toolbox-text.png" width="130px"\&gt;
&lt;/div&gt;
&lt;/div&gt;

---

# Transfer Learning: NLP

.Large[
* Word embeddings
  * word2vec
  * GloVe
* king − man + woman ≅ queen
]

---

count: false

# Transfer Learning: NLP

.Large[
* Word embeddings
  * word2vec
  * GloVe
* king − man + woman ≅ queen
* Problem: 
  * "I saw the *branch* on the *bank*" vs 
  * "I saw the *branch* of the *bank*"
]

---

# BERT

.Large[
* **B**idirectional **E**ncoder **R**epresentations from **T**ransformers
* Initially released October 11, 2018
  * Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova from Google AI Language
* Trained with a very large corpus
* Transferable!
]

---

# RBERT

.pull-left[
.Large[
* Implementation of BERT in R
* Use for:
  * Feature extraction (text to high-dimensional vectors)
  * Soon: Fine-tuning
]
]

.pull-right[
&lt;img src="img/rbert_hex.png" width="400px"&gt;
]

---

# RBERTviz

.pull-left[
.Large[
* Helper package
* Visualize how BERT "thinks"
  * `visualize_attention`
  * `display_pca`
]
]

.pull-right[
&lt;img src="img/RBERTviz.png" width="400px"&gt;
]

---

# Attention

.pull-left[

```r
RBERT::download_BERT_checkpoint(
  "bert_base_uncased"
)
RBERT::extract_features(
  "I love tacos.",
  model = "bert_base_uncased",
  layer_indexes = 1:12,
  features = "attention"
)$attention %&gt;%
  RBERTviz::visualize_attention()
```
]
.pull-right[
&lt;img src="img/attention/tacos.png", width="500px"/&gt;
]

[Live demo](tacos_viz.html)

---

# Attention

.Large[
Sentences:

* The chicken didn't cross the road because it was too tired.
* The chicken didn't cross the road because it was too wide.
* The dog fetched the ball. It was excited.
* The dog fetched the ball. It was blue.
]

---

count: false

# Attention

.Large[
Sentences:

* The chicken didn't cross the road because it was too **tired**.
* The chicken didn't cross the road because it was too **wide**.
* The dog fetched the ball. It was **excited**.
* The dog fetched the ball. It was **blue**.
]

---

count: false

# Attention

.Large[
Sentences:

* The **chicken** didn't cross the road because **it** was too **tired.**
* The chicken didn't cross the **road** because **it** was too **wide.**
* The **dog** fetched the ball. **It** was **excited.**
* The dog fetched the **ball.** **It** was **blue.**
]

---

# Attention

&lt;img src="img/attention/3_1-chicken_tired.png"&gt;

.Large[Early: Position (≈ edge detector)]

---

count: false

# Attention

&lt;img src="img/attention/3_1-chicken_tired.png" width="250px"&gt;
&lt;img src="img/attention/3_1-chicken_wide.png" width="250px"&gt;
&lt;img src="img/attention/3_1-dog_excited.png" width="250px"&gt;
&lt;img src="img/attention/3_1-dog_blue.png" width="250px"&gt;

.Large[Early: Position (≈ edge detector)]

---

# Attention

&lt;img src="img/attention/9_5-chicken_tired.png"&gt;

.Large[Later: Pronoun Resolution (≈ face detector)]

---

count: false

# Attention

&lt;img src="img/attention/9_5-chicken_tired.png" width="250px"&gt;
&lt;img src="img/attention/9_5-chicken_wide.png" width="250px"&gt;
&lt;img src="img/attention/9_5-dog_excited.png" width="250px"&gt;
&lt;img src="img/attention/9_5-dog_blue.png" width="250px"&gt;

.Large[Later: Pronoun Resolution (≈ face detector)]

---

# Layer Outputs

.pull-left[
.Large[
Online survey:

* "A single sentence about learning, WITH the word 'train' (or 'trained', 'training', etc, meaning 'teach')."
* "A single sentence about travel, WITH the word 'train' (as in the vehicle)."
]]

.pull-right[

```r
trains_data &lt;- readRDS("trains_data.rds") %&gt;%
  dplyr::mutate(
    sequence_index = dplyr::row_number()
  )

trains_output &lt;- RBERT::extract_features(
  trains_data$sentence,
  model = "bert_base_uncased",
  layer_indexes = 0:12,
  features = "output"
)$output

trains_output_labeled &lt;- trains_output %&gt;%
  dplyr::left_join(
    dplyr::select(
      trains_data, 
      sequence_index, label
    ),
    by = "sequence_index"
  )
```
]



---

# Layer Outputs

.pull-left[


```r
trains_output_labeled %&gt;% 
  RBERTviz::display_pca(
    token_filter = "^train",
    layer_index = 0,
    # Just show one example of each unique word
    distinct_tokens = TRUE
  )
```
]

.pull-right[
&lt;img src="rbert_files/figure-html/layer-0-plot-1.png" width="504" /&gt;
]

---

# Layer Outputs

Layer 0 (initial vectors)

&lt;img src="rbert_files/figure-html/layer-0-labeled-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 1

&lt;img src="rbert_files/figure-html/layer-1-1.png" width="1080" /&gt;
&lt;img src="rbert_files/figure-html/unnamed-chunk-1-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 2

&lt;img src="rbert_files/figure-html/layer-2-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 3

&lt;img src="rbert_files/figure-html/layer-3-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 4

&lt;img src="rbert_files/figure-html/layer-4-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 5

&lt;img src="rbert_files/figure-html/layer-5-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 6

&lt;img src="rbert_files/figure-html/layer-6-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 7

&lt;img src="rbert_files/figure-html/layer-7-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 8

&lt;img src="rbert_files/figure-html/layer-8-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 9

&lt;img src="rbert_files/figure-html/layer-9-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 10

&lt;img src="rbert_files/figure-html/layer-10-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

Layer 11

&lt;img src="rbert_files/figure-html/layer-11-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

wait a minute...

&lt;img src="rbert_files/figure-html/highlight-bad-1.png" width="1080" /&gt;
---
count: false

# Layer Outputs

wait a minute...

&lt;img src="rbert_files/figure-html/highlight-bad2-1.png" width="1080" /&gt;
---

# To Do

.Large[
* RBERT is usable *now*...
* ...but it can be *better!*
* Goal: CRAN by end of 2019
  * tensorflow 2.0 (in testing)
  * More Rtful, less pythonic
  * Recipe: `step_bert_features()`
* Rstudio::conf(2020L) e-poster
* Poster ideas? [bit.ly/rbertposter](http://bit.ly/rbertposter)
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
